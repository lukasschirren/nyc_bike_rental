{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessible dataframes    Description                            # of columns  \n",
      "data_2019                Gives data for 2019-Baseline           15\n",
      "data_2024                Gives data for 2024                    13\n",
      "station_data             Existing stations in NYC from Lyft      6\n"
     ]
    }
   ],
   "source": [
    "##Preparation\n",
    "\n",
    "%run functions.ipynb\n",
    "%run data_preparation.ipynb\n",
    "\n",
    "# base_folder_path = '/workspaces/nyc_bike_rental//data'\n",
    "# start_year = 2015\n",
    "# end_year = 2019\n",
    "#combined_data = combine_csv_files_in_years(base_folder_path,start_year,end_year)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_name</th>\n",
       "      <th>name</th>\n",
       "      <th>region_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6215.04</td>\n",
       "      <td>W 25 St &amp; 6 Ave</td>\n",
       "      <td>71</td>\n",
       "      <td>40.743954</td>\n",
       "      <td>-73.991449</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5216.06</td>\n",
       "      <td>Vesey St &amp; Church St</td>\n",
       "      <td>71</td>\n",
       "      <td>40.712220</td>\n",
       "      <td>-74.010472</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4129.10</td>\n",
       "      <td>Herkimer St &amp; Eastern Pkwy</td>\n",
       "      <td>71</td>\n",
       "      <td>40.677380</td>\n",
       "      <td>-73.908290</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8262.07</td>\n",
       "      <td>W 171 St &amp; St Nicholas Ave</td>\n",
       "      <td>71</td>\n",
       "      <td>40.842941</td>\n",
       "      <td>-73.938631</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8467.03</td>\n",
       "      <td>E 184 St &amp; 3 Ave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.854720</td>\n",
       "      <td>-73.890220</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>HB201</td>\n",
       "      <td>12 St &amp; Sinatra Dr N</td>\n",
       "      <td>311</td>\n",
       "      <td>40.750604</td>\n",
       "      <td>-74.024020</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>JC084</td>\n",
       "      <td>Communipaw &amp; Berry Lane</td>\n",
       "      <td>70</td>\n",
       "      <td>40.714358</td>\n",
       "      <td>-74.066611</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>HB302</td>\n",
       "      <td>6 St &amp; Grand St</td>\n",
       "      <td>311</td>\n",
       "      <td>40.744398</td>\n",
       "      <td>-74.034501</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>HB603</td>\n",
       "      <td>8 St &amp; Washington St</td>\n",
       "      <td>311</td>\n",
       "      <td>40.745984</td>\n",
       "      <td>-74.028199</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>JC006</td>\n",
       "      <td>Warren St</td>\n",
       "      <td>70</td>\n",
       "      <td>40.721124</td>\n",
       "      <td>-74.038051</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2208 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     short_name                        name region_id        lat        lon  \\\n",
       "0       6215.04             W 25 St & 6 Ave        71  40.743954 -73.991449   \n",
       "1       5216.06        Vesey St & Church St        71  40.712220 -74.010472   \n",
       "2       4129.10  Herkimer St & Eastern Pkwy        71  40.677380 -73.908290   \n",
       "3       8262.07  W 171 St & St Nicholas Ave        71  40.842941 -73.938631   \n",
       "4       8467.03            E 184 St & 3 Ave       NaN  40.854720 -73.890220   \n",
       "...         ...                         ...       ...        ...        ...   \n",
       "2203      HB201        12 St & Sinatra Dr N       311  40.750604 -74.024020   \n",
       "2204      JC084     Communipaw & Berry Lane        70  40.714358 -74.066611   \n",
       "2205      HB302             6 St & Grand St       311  40.744398 -74.034501   \n",
       "2206      HB603        8 St & Washington St       311  40.745984 -74.028199   \n",
       "2207      JC006                   Warren St        70  40.721124 -74.038051   \n",
       "\n",
       "      capacity  \n",
       "0           51  \n",
       "1           48  \n",
       "2           20  \n",
       "3           31  \n",
       "4           19  \n",
       "...        ...  \n",
       "2203        28  \n",
       "2204        14  \n",
       "2205        18  \n",
       "2206        21  \n",
       "2207        22  \n",
       "\n",
       "[2208 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start station id</th>\n",
       "      <th>start station name</th>\n",
       "      <th>start station latitude</th>\n",
       "      <th>start station longitude</th>\n",
       "      <th>end station id</th>\n",
       "      <th>end station name</th>\n",
       "      <th>end station latitude</th>\n",
       "      <th>end station longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birth year</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570</td>\n",
       "      <td>2019-10-16 08:11:16.991</td>\n",
       "      <td>2019-10-16 08:20:47.367</td>\n",
       "      <td>453.0</td>\n",
       "      <td>W 22 St &amp; 8 Ave</td>\n",
       "      <td>40.744751</td>\n",
       "      <td>-73.999154</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>E 41 St &amp; Madison Ave</td>\n",
       "      <td>40.752165</td>\n",
       "      <td>-73.979922</td>\n",
       "      <td>15131</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>657</td>\n",
       "      <td>2019-10-16 08:11:17.547</td>\n",
       "      <td>2019-10-16 08:22:15.194</td>\n",
       "      <td>212.0</td>\n",
       "      <td>W 16 St &amp; The High Line</td>\n",
       "      <td>40.743349</td>\n",
       "      <td>-74.006818</td>\n",
       "      <td>426.0</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>40.717548</td>\n",
       "      <td>-74.013221</td>\n",
       "      <td>33833</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>610</td>\n",
       "      <td>2019-10-16 08:11:17.753</td>\n",
       "      <td>2019-10-16 08:21:28.747</td>\n",
       "      <td>466.0</td>\n",
       "      <td>W 25 St &amp; 6 Ave</td>\n",
       "      <td>40.743954</td>\n",
       "      <td>-73.991449</td>\n",
       "      <td>519.0</td>\n",
       "      <td>Pershing Square North</td>\n",
       "      <td>40.751873</td>\n",
       "      <td>-73.977706</td>\n",
       "      <td>35074</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>379</td>\n",
       "      <td>2019-10-16 08:11:17.801</td>\n",
       "      <td>2019-10-16 08:17:37.146</td>\n",
       "      <td>3646.0</td>\n",
       "      <td>35 Ave &amp; 10 St</td>\n",
       "      <td>40.763155</td>\n",
       "      <td>-73.939855</td>\n",
       "      <td>3130.0</td>\n",
       "      <td>21 St &amp; Queens Plaza North</td>\n",
       "      <td>40.753260</td>\n",
       "      <td>-73.943358</td>\n",
       "      <td>40940</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1986</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>329</td>\n",
       "      <td>2019-10-16 08:11:17.815</td>\n",
       "      <td>2019-10-16 08:16:46.876</td>\n",
       "      <td>319.0</td>\n",
       "      <td>Fulton St &amp; Broadway</td>\n",
       "      <td>40.711066</td>\n",
       "      <td>-74.009447</td>\n",
       "      <td>415.0</td>\n",
       "      <td>Pearl St &amp; Hanover Square</td>\n",
       "      <td>40.704718</td>\n",
       "      <td>-74.009260</td>\n",
       "      <td>40993</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20551692</th>\n",
       "      <td>445</td>\n",
       "      <td>2019-04-04 08:24:17.464</td>\n",
       "      <td>2019-04-04 08:31:42.697</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>Nassau Ave &amp; Newell St</td>\n",
       "      <td>40.724813</td>\n",
       "      <td>-73.947526</td>\n",
       "      <td>3715.0</td>\n",
       "      <td>Driggs Ave &amp; N 9 St</td>\n",
       "      <td>40.718170</td>\n",
       "      <td>-73.955201</td>\n",
       "      <td>34930</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1985</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20551693</th>\n",
       "      <td>282</td>\n",
       "      <td>2019-04-04 08:24:14.827</td>\n",
       "      <td>2019-04-04 08:28:57.386</td>\n",
       "      <td>347.0</td>\n",
       "      <td>Greenwich St &amp; W Houston St</td>\n",
       "      <td>40.728846</td>\n",
       "      <td>-74.008591</td>\n",
       "      <td>426.0</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>40.717548</td>\n",
       "      <td>-74.013221</td>\n",
       "      <td>36794</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20551694</th>\n",
       "      <td>485</td>\n",
       "      <td>2019-04-04 08:24:13.146</td>\n",
       "      <td>2019-04-04 08:32:18.783</td>\n",
       "      <td>3093.0</td>\n",
       "      <td>N 6 St &amp; Bedford Ave</td>\n",
       "      <td>40.717452</td>\n",
       "      <td>-73.958509</td>\n",
       "      <td>282.0</td>\n",
       "      <td>Kent Ave &amp; S 11 St</td>\n",
       "      <td>40.707645</td>\n",
       "      <td>-73.968415</td>\n",
       "      <td>31045</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1981</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20551695</th>\n",
       "      <td>1749</td>\n",
       "      <td>2019-04-04 08:24:13.304</td>\n",
       "      <td>2019-04-04 08:53:22.334</td>\n",
       "      <td>3629.0</td>\n",
       "      <td>Adam Clayton Powell Blvd &amp; W 126 St</td>\n",
       "      <td>40.809495</td>\n",
       "      <td>-73.947765</td>\n",
       "      <td>479.0</td>\n",
       "      <td>9 Ave &amp; W 45 St</td>\n",
       "      <td>40.760193</td>\n",
       "      <td>-73.991255</td>\n",
       "      <td>36116</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1984</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20551696</th>\n",
       "      <td>329</td>\n",
       "      <td>2019-04-04 08:24:25.548</td>\n",
       "      <td>2019-04-04 08:29:55.399</td>\n",
       "      <td>238.0</td>\n",
       "      <td>Bank St &amp; Washington St</td>\n",
       "      <td>40.736197</td>\n",
       "      <td>-74.008592</td>\n",
       "      <td>435.0</td>\n",
       "      <td>W 21 St &amp; 6 Ave</td>\n",
       "      <td>40.741740</td>\n",
       "      <td>-73.994156</td>\n",
       "      <td>36806</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1951</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20551697 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tripduration               starttime                stoptime  \\\n",
       "0                  570 2019-10-16 08:11:16.991 2019-10-16 08:20:47.367   \n",
       "1                  657 2019-10-16 08:11:17.547 2019-10-16 08:22:15.194   \n",
       "2                  610 2019-10-16 08:11:17.753 2019-10-16 08:21:28.747   \n",
       "3                  379 2019-10-16 08:11:17.801 2019-10-16 08:17:37.146   \n",
       "4                  329 2019-10-16 08:11:17.815 2019-10-16 08:16:46.876   \n",
       "...                ...                     ...                     ...   \n",
       "20551692           445 2019-04-04 08:24:17.464 2019-04-04 08:31:42.697   \n",
       "20551693           282 2019-04-04 08:24:14.827 2019-04-04 08:28:57.386   \n",
       "20551694           485 2019-04-04 08:24:13.146 2019-04-04 08:32:18.783   \n",
       "20551695          1749 2019-04-04 08:24:13.304 2019-04-04 08:53:22.334   \n",
       "20551696           329 2019-04-04 08:24:25.548 2019-04-04 08:29:55.399   \n",
       "\n",
       "          start station id                   start station name  \\\n",
       "0                    453.0                      W 22 St & 8 Ave   \n",
       "1                    212.0              W 16 St & The High Line   \n",
       "2                    466.0                      W 25 St & 6 Ave   \n",
       "3                   3646.0                       35 Ave & 10 St   \n",
       "4                    319.0                 Fulton St & Broadway   \n",
       "...                    ...                                  ...   \n",
       "20551692            3100.0               Nassau Ave & Newell St   \n",
       "20551693             347.0          Greenwich St & W Houston St   \n",
       "20551694            3093.0                 N 6 St & Bedford Ave   \n",
       "20551695            3629.0  Adam Clayton Powell Blvd & W 126 St   \n",
       "20551696             238.0              Bank St & Washington St   \n",
       "\n",
       "          start station latitude  start station longitude  end station id  \\\n",
       "0                      40.744751               -73.999154          3235.0   \n",
       "1                      40.743349               -74.006818           426.0   \n",
       "2                      40.743954               -73.991449           519.0   \n",
       "3                      40.763155               -73.939855          3130.0   \n",
       "4                      40.711066               -74.009447           415.0   \n",
       "...                          ...                      ...             ...   \n",
       "20551692               40.724813               -73.947526          3715.0   \n",
       "20551693               40.728846               -74.008591           426.0   \n",
       "20551694               40.717452               -73.958509           282.0   \n",
       "20551695               40.809495               -73.947765           479.0   \n",
       "20551696               40.736197               -74.008592           435.0   \n",
       "\n",
       "                    end station name  end station latitude  \\\n",
       "0              E 41 St & Madison Ave             40.752165   \n",
       "1              West St & Chambers St             40.717548   \n",
       "2              Pershing Square North             40.751873   \n",
       "3         21 St & Queens Plaza North             40.753260   \n",
       "4          Pearl St & Hanover Square             40.704718   \n",
       "...                              ...                   ...   \n",
       "20551692         Driggs Ave & N 9 St             40.718170   \n",
       "20551693       West St & Chambers St             40.717548   \n",
       "20551694          Kent Ave & S 11 St             40.707645   \n",
       "20551695             9 Ave & W 45 St             40.760193   \n",
       "20551696             W 21 St & 6 Ave             40.741740   \n",
       "\n",
       "          end station longitude bikeid    usertype  birth year gender  \n",
       "0                    -73.979922  15131  Subscriber        1974      1  \n",
       "1                    -74.013221  33833  Subscriber        1994      1  \n",
       "2                    -73.977706  35074  Subscriber        1995      1  \n",
       "3                    -73.943358  40940  Subscriber        1986      2  \n",
       "4                    -74.009260  40993  Subscriber        1966      1  \n",
       "...                         ...    ...         ...         ...    ...  \n",
       "20551692             -73.955201  34930  Subscriber        1985      2  \n",
       "20551693             -74.013221  36794  Subscriber        1988      1  \n",
       "20551694             -73.968415  31045  Subscriber        1981      2  \n",
       "20551695             -73.991255  36116  Subscriber        1984      1  \n",
       "20551696             -73.994156  36806  Subscriber        1951      1  \n",
       "\n",
       "[20551697 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start station name\n",
      "Pershing Square North        156575\n",
      "E 17 St & Broadway           121781\n",
      "8 Ave & W 31 St              119958\n",
      "Broadway & E 22 St           113138\n",
      "Broadway & E 14 St           113012\n",
      "                              ...  \n",
      "Somers St & Broadway              8\n",
      "Madison St & Woodward Ave         6\n",
      "NYCBS DEPOT - DELANCEY            6\n",
      "58th St Depot                     6\n",
      "W 39 St & 9 Ave                   3\n",
      "Name: count, Length: 938, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count_total_stations=data_2019['start station name'].value_counts()\n",
    "print(count_total_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 first stations with the highest demand (in terms of starting stations) on weekends\n",
      "start station name\n",
      "Broadway & W 60 St                   300\n",
      "E 17 St & Broadway                   282\n",
      "West St & Chambers St                280\n",
      "Broadway & E 14 St                   279\n",
      "12 Ave & W 40 St                     272\n",
      "W 21 St & 6 Ave                      250\n",
      "Central Park S & 6 Ave               248\n",
      "Christopher St & Greenwich St        240\n",
      "W 20 St & 11 Ave                     237\n",
      "Cleveland Pl & Spring St             228\n",
      "Pier 40 - Hudson River Park          225\n",
      "Grand St & Elizabeth St              222\n",
      "South End Ave & Liberty St           216\n",
      "E 13 St & Avenue A                   216\n",
      "Carmine St & 6 Ave                   215\n",
      "Grand Army Plaza & Central Park S    212\n",
      "Lafayette St & E 8 St                210\n",
      "W 4 St & 7 Ave S                     206\n",
      "Washington St & Gansevoort St        205\n",
      "5 Ave & E 88 St                      200\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "##WEEKENDS\n",
    "\n",
    "data_2019['starttime'] = pd.to_datetime(data_2019['starttime'])\n",
    "data_2019['day_of_week'] = data_2019['starttime'].dt.dayofweek  # 0: Monday, 1: Tuesday, ..., 6: Sunday\n",
    "num_weekends_2019 = len(data_2019[(data_2019['day_of_week'] >= 5) & (data_2019['day_of_week'] <= 6)]['starttime'].dt.date.unique())\n",
    "\n",
    "# 1) Average throughout the weekend\n",
    "\n",
    "weekends_average_data = data_2019[(data_2019['day_of_week'] >= 5) & (data_2019['day_of_week'] <= 6)]\n",
    "weekends_station_counts = weekends_average_data['start station name'].value_counts()\n",
    "average_weekends = (weekends_station_counts/num_weekends_2019).round(0).astype(int)\n",
    "\n",
    "print(\"10 first stations with the highest demand (in terms of starting stations) on weekends\")\n",
    "print(average_weekends.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 first stations with the highest demand (in terms of starting stations) on weekends from 6am to 10am\n",
      "start station name\n",
      "E 13 St & Avenue A               25\n",
      "1 Ave & E 16 St                  24\n",
      "1 Ave & E 18 St                  24\n",
      "Broadway & W 60 St               22\n",
      "11 Ave & W 41 St                 21\n",
      "W 41 St & 8 Ave                  20\n",
      "Christopher St & Greenwich St    20\n",
      "Central Park S & 6 Ave           20\n",
      "West St & Chambers St            20\n",
      "Columbus Ave & W 72 St           19\n",
      "W 21 St & 6 Ave                  19\n",
      "South End Ave & Liberty St       19\n",
      "E 17 St & Broadway               19\n",
      "E 23 St & 1 Ave                  19\n",
      "E 25 St & 2 Ave                  19\n",
      "E 20 St & FDR Drive              18\n",
      "1 Ave & E 78 St                  18\n",
      "Broadway & E 14 St               18\n",
      "E 20 St & 2 Ave                  18\n",
      "W 22 St & 8 Ave                  18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2) Average from 6am to 10am\n",
    "\n",
    "weekends_morning_data = data_2019[(data_2019['day_of_week'] >= 5) & (data_2019['day_of_week'] <= 6) & (data_2019['starttime'].dt.hour >= 6) & (data_2019['starttime'].dt.hour < 10)]\n",
    "weekends_morning_counts = weekends_morning_data['start station name'].value_counts()\n",
    "weekends_morning = (weekends_morning_counts/num_weekends_2019).round(0).astype(int)\n",
    "\n",
    "print(\"10 first stations with the highest demand (in terms of starting stations) on weekends from 6am to 10am\")\n",
    "print(weekends_morning.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 first stations with the highest demand (in terms of starting stations) on weekends from 10am to 2pm\n",
      "start station name\n",
      "Broadway & W 60 St                   90\n",
      "12 Ave & W 40 St                     89\n",
      "E 17 St & Broadway                   88\n",
      "West St & Chambers St                83\n",
      "Central Park S & 6 Ave               80\n",
      "W 21 St & 6 Ave                      75\n",
      "Broadway & E 14 St                   75\n",
      "Grand Army Plaza & Central Park S    73\n",
      "Christopher St & Greenwich St        71\n",
      "South End Ave & Liberty St           66\n",
      "W 20 St & 11 Ave                     65\n",
      "E 10 St & Avenue A                   65\n",
      "Cleveland Pl & Spring St             65\n",
      "E 13 St & Avenue A                   64\n",
      "5 Ave & E 88 St                      64\n",
      "Lafayette St & E 8 St                61\n",
      "Grand St & Elizabeth St              61\n",
      "Pier 40 - Hudson River Park          61\n",
      "Broadway & E 22 St                   60\n",
      "E 11 St & 1 Ave                      59\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3) Average from 10am to 2pm\n",
    "\n",
    "weekends_noon_data = data_2019[(data_2019['day_of_week'] >= 5) & (data_2019['day_of_week'] <= 6) & (data_2019['starttime'].dt.hour >= 10) & (data_2019['starttime'].dt.hour < 14)]\n",
    "weekends_noon_counts = weekends_noon_data['start station name'].value_counts()\n",
    "weekends_noon = (weekends_noon_counts/num_weekends_2019).round(0).astype(int)\n",
    "\n",
    "print(\"10 first stations with the highest demand (in terms of starting stations) on weekends from 10am to 2pm\")\n",
    "print(weekends_noon.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 first stations with the highest demand (in terms of starting stations) on weekends from 2pm to 6pm\n",
      "start station name\n",
      "Broadway & W 60 St                   113\n",
      "West St & Chambers St                108\n",
      "12 Ave & W 40 St                     107\n",
      "E 17 St & Broadway                   103\n",
      "Broadway & E 14 St                    95\n",
      "Central Park S & 6 Ave                94\n",
      "W 20 St & 11 Ave                      94\n",
      "Pier 40 - Hudson River Park           90\n",
      "5 Ave & E 88 St                       89\n",
      "W 34 St & 11 Ave                      86\n",
      "W 21 St & 6 Ave                       85\n",
      "Grand Army Plaza & Central Park S     84\n",
      "Christopher St & Greenwich St         82\n",
      "South End Ave & Liberty St            80\n",
      "Cleveland Pl & Spring St              79\n",
      "Washington St & Gansevoort St         79\n",
      "Grand St & Elizabeth St               78\n",
      "Central Park West & W 72 St           77\n",
      "5 Ave & E 73 St                       76\n",
      "Broadway & E 22 St                    73\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4) Average from 2pm to 6pm\n",
    "\n",
    "weekends_afternoon_data = data_2019[(data_2019['day_of_week'] >= 5) & (data_2019['day_of_week'] <= 6) & (data_2019['starttime'].dt.hour >= 14) & (data_2019['starttime'].dt.hour < 18)]\n",
    "weekends_afternoon_counts = weekends_afternoon_data['start station name'].value_counts()\n",
    "weekends_afternoon = (weekends_afternoon_counts/num_weekends_2019).round(0).astype(int)\n",
    "\n",
    "print(\"10 first stations with the highest demand (in terms of starting stations) on weekends from 2pm to 6pm\")\n",
    "print(weekends_afternoon.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 first stations with the highest demand (in terms of starting stations) on weekends from 6pm to 10pm\n",
      "start station name\n",
      "Broadway & E 14 St               63\n",
      "Broadway & W 60 St               57\n",
      "West St & Chambers St            57\n",
      "W 21 St & 6 Ave                  55\n",
      "W 20 St & 11 Ave                 55\n",
      "E 17 St & Broadway               54\n",
      "Pier 40 - Hudson River Park      52\n",
      "Cleveland Pl & Spring St         50\n",
      "12 Ave & W 40 St                 50\n",
      "Christopher St & Greenwich St    49\n",
      "Grand St & Elizabeth St          48\n",
      "Carmine St & 6 Ave               47\n",
      "Lafayette St & E 8 St            46\n",
      "W 4 St & 7 Ave S                 44\n",
      "E 13 St & Avenue A               43\n",
      "Central Park S & 6 Ave           43\n",
      "South End Ave & Liberty St       41\n",
      "Washington St & Gansevoort St    40\n",
      "Broadway & E 22 St               40\n",
      "E 11 St & 1 Ave                  39\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 5) Average from 6pm to 10pm\n",
    "\n",
    "weekends_evening_data = data_2019[(data_2019['day_of_week'] >= 5) & (data_2019['day_of_week'] <= 6) & (data_2019['starttime'].dt.hour >= 18) & (data_2019['starttime'].dt.hour < 22)]\n",
    "weekends_evening_counts = weekends_evening_data['start station name'].value_counts()\n",
    "weekends_evening = (weekends_evening_counts/num_weekends_2019).round(0).astype(int)\n",
    "\n",
    "print(\"10 first stations with the highest demand (in terms of starting stations) on weekends from 6pm to 10pm\")\n",
    "print(weekends_evening.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 stations with the highest demand per day (in terms of starting stations) during the week\n",
      "start station name\n",
      "Pershing Square North            532\n",
      "8 Ave & W 31 St                  400\n",
      "Broadway & E 22 St               355\n",
      "E 17 St & Broadway               354\n",
      "W 21 St & 6 Ave                  323\n",
      "Broadway & E 14 St               322\n",
      "8 Ave & W 33 St                  302\n",
      "E 47 St & Park Ave               299\n",
      "W 41 St & 8 Ave                  295\n",
      "West St & Chambers St            293\n",
      "Christopher St & Greenwich St    293\n",
      "W 38 St & 8 Ave                  284\n",
      "W 31 St & 7 Ave                  278\n",
      "W 20 St & 11 Ave                 277\n",
      "Broadway & W 41 St               276\n",
      "Broadway & W 60 St               276\n",
      "Lafayette St & E 8 St            276\n",
      "Broadway & W 25 St               275\n",
      "12 Ave & W 40 St                 272\n",
      "E 24 St & Park Ave S             267\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#WEEKDAYS \n",
    "\n",
    "data_2019['starttime'] = pd.to_datetime(data_2019['starttime'])\n",
    "data_2019['day_of_week'] = data_2019['starttime'].dt.dayofweek\n",
    "\n",
    "\n",
    "# 1) Average throughout the week\n",
    "\n",
    "weekdays_average_data = data_2019[(data_2019['day_of_week'] >= 0) & (data_2019['day_of_week'] <= 4)]\n",
    "weekdays_average_counts = weekdays_average_data['start station name'].value_counts()\n",
    "num_weekdays_2019 = len(weekdays_average_data['starttime'].dt.date.unique())\n",
    "average_weekdays = (weekdays_average_counts / num_weekdays_2019).round(0).astype(int)\n",
    "\n",
    "print(\"Top 10 stations with the highest demand per day (in terms of starting stations) during the week\")\n",
    "print(average_weekdays.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of departures per station for days of the week and hours between 6 a.m. and 10 a.m. in 2019:\n",
      "start station name\n",
      "8 Ave & W 31 St                  212\n",
      "Pershing Square North            169\n",
      "Christopher St & Greenwich St    114\n",
      "12 Ave & W 40 St                 106\n",
      "Broadway & W 41 St                95\n",
      "8 Ave & W 33 St                   91\n",
      "E 13 St & Avenue A                88\n",
      "1 Ave & E 16 St                   83\n",
      "W 31 St & 7 Ave                   82\n",
      "E 10 St & Avenue A                81\n",
      "E 47 St & Park Ave                78\n",
      "W 38 St & 8 Ave                   74\n",
      "E 20 St & FDR Drive               74\n",
      "Pershing Square South             74\n",
      "St Marks Pl & 1 Ave               73\n",
      "E 2 St & Avenue B                 71\n",
      "FDR Drive & E 35 St               68\n",
      "Columbus Ave & W 72 St            68\n",
      "W 33 St & 7 Ave                   67\n",
      "E 20 St & 2 Ave                   67\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2) From 6am to 10am\n",
    "\n",
    "weekday_morning_data = data_2019[(data_2019['day_of_week'] >= 0) & (data_2019['day_of_week'] <= 4) & (data_2019['starttime'].dt.hour >= 6) & (data_2019['starttime'].dt.hour < 10)]\n",
    "weekday_morning_station_counts = weekday_morning_data['start station name'].value_counts()\n",
    "average_weekday_morning = (weekday_morning_station_counts / num_weekdays_2019).round(0).astype(int)\n",
    "\n",
    "print(\"Average number of departures per station for days of the week and hours between 6 a.m. and 10 a.m. in 2019:\")\n",
    "print(average_weekday_morning.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of departures per station for days of the week and hours between 4 p.m. and 8 p.m. in 2019:\n",
      "start station name\n",
      "Pershing Square North            227\n",
      "Broadway & E 22 St               183\n",
      "E 47 St & Park Ave               158\n",
      "North Moore St & Greenwich St    146\n",
      "E 17 St & Broadway               145\n",
      "West St & Chambers St            133\n",
      "E 24 St & Park Ave S             130\n",
      "W 21 St & 6 Ave                  122\n",
      "Broadway & E 14 St               117\n",
      "W 41 St & 8 Ave                  116\n",
      "W 20 St & 11 Ave                 113\n",
      "Broadway & W 25 St               112\n",
      "E 48 St & 5 Ave                  112\n",
      "W 18 St & 6 Ave                  108\n",
      "W 38 St & 8 Ave                  107\n",
      "W 31 St & 7 Ave                  104\n",
      "W 52 St & 5 Ave                  104\n",
      "W 52 St & 6 Ave                  102\n",
      "Lafayette St & E 8 St            102\n",
      "Broadway & W 60 St               101\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3) From 4pm to 8pm\n",
    "\n",
    "weekday_evening_data = data_2019[(data_2019['day_of_week'] >= 0) & (data_2019['day_of_week'] <= 4) & (data_2019['starttime'].dt.hour >= 16) & (data_2019['starttime'].dt.hour < 20)]\n",
    "weekday_evening_station_counts = weekday_evening_data['start station name'].value_counts()\n",
    "average_weekday_evening = (weekday_evening_station_counts / num_weekdays_2019).round(0).astype(int)\n",
    "\n",
    "print(\"Average number of departures per station for days of the week and hours between 4 p.m. and 8 p.m. in 2019:\")\n",
    "print(average_weekday_evening.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data in the Excel file 'Bike_demand.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "demand_excel_file = \"Bike_demand.xlsx\"\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(demand_excel_file) as writer:\n",
    "    average_weekdays.to_excel(writer, sheet_name='Feuille1', index=True)\n",
    "    average_weekday_morning.to_excel(writer, sheet_name='Feuille1', startcol=3, index=True)\n",
    "    average_weekday_evening.to_excel(writer, sheet_name='Feuille1', startcol=5, index=True)\n",
    "\n",
    "    average_weekends.to_excel(writer, sheet_name='Feuille2', index=True)\n",
    "    weekends_morning.to_excel(writer, sheet_name='Feuille2', startcol=3, index=True)\n",
    "    weekends_noon.to_excel(writer, sheet_name='Feuille2', startcol=5, index=True)\n",
    "    weekends_afternoon.to_excel(writer, sheet_name='Feuille2', startcol=7, index=True)\n",
    "    weekends_evening.to_excel(writer, sheet_name='Feuille2', startcol=9, index=True)\n",
    "\n",
    "\n",
    "print(f\"Data in the Excel file '{demand_excel_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [short_name, name, region_id, lat, lon, capacity]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(station_row)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Extraire les coordonnées (latitude et longitude)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m latitude \u001b[38;5;241m=\u001b[39m station_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(latitude)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "station_row = station_data.loc[station_data['name'] == 'Broadway & W 60 St']\n",
    "print(station_row)\n",
    "    # Extraire les coordonnées (latitude et longitude)\n",
    "latitude = station_row['lat'].values[0]\n",
    "print(latitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "def distance_lat_long(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000.0\n",
    "\n",
    "    \n",
    "    lat1_rad = radians(lat1)\n",
    "    lon1_rad = radians(lon1)\n",
    "    lat2_rad = radians(lat2)\n",
    "    lon2_rad = radians(lon2)\n",
    "\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1_rad) * cos(lat2_rad) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance = R * c\n",
    "\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Line Borough     Station Name  Station Latitude  \\\n",
      "0    42nd St Shuttle       M    Grand Central         40.752769   \n",
      "1    42nd St Shuttle       M     Times Square         40.755983   \n",
      "2             4th Av       B       Pacific St         40.683666   \n",
      "3             4th Av       B         Union St         40.677316   \n",
      "4             4th Av       B      Lawrence St         40.692180   \n",
      "..               ...     ...              ...               ...   \n",
      "351  White Plains Rd      Bx       Simpson St         40.824073   \n",
      "352  White Plains Rd      Bx     Intervale Av         40.822181   \n",
      "353  White Plains Rd      Bx      Prospect Av         40.819585   \n",
      "354  White Plains Rd      Bx       Jackson Av         40.816490   \n",
      "355  White Plains Rd      Bx  149th St-3rd Av         40.816109   \n",
      "\n",
      "     Station Longitude  surrounding bike stations  \n",
      "0           -73.979189                       52.0  \n",
      "1           -73.986229                       54.0  \n",
      "2           -73.978810                       39.0  \n",
      "3           -73.983110                       36.0  \n",
      "4           -73.985942                       46.0  \n",
      "..                 ...                        ...  \n",
      "351         -73.893064                       31.0  \n",
      "352         -73.896736                       31.0  \n",
      "353         -73.901770                       32.0  \n",
      "354         -73.907807                       34.0  \n",
      "355         -73.917757                       37.0  \n",
      "\n",
      "[356 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "subway_station = pd.read_excel(\"Subway_stations_nyc.xlsx\", usecols=\"A:E\")\n",
    "\n",
    "# Renommer la colonne en 'surrounding bike stations'\n",
    "subway_station.rename(columns={'Count': 'surrounding bike stations'}, inplace=True)\n",
    "\n",
    "\n",
    "# Boucle à travers chaque ligne de subway_station\n",
    "for index, row in subway_station.iterrows():\n",
    "    lat2 = row['Station Latitude']\n",
    "    lon2 = row['Station Longitude']\n",
    "    count = 0\n",
    "\n",
    "    # Boucle à travers chaque ligne de station_data\n",
    "    for index2, row2 in station_data.iterrows():\n",
    "        lat1 = row2['lat']\n",
    "        lon1 = row2['lon']\n",
    "        distance = distance_lat_long(lat1, lon1, lat2, lon2)\n",
    "        \n",
    "        # Vérifier si la distance est inférieure à 1000\n",
    "        if distance < 1000:\n",
    "            count += 1\n",
    "    \n",
    "    # Mettre à jour la valeur dans la colonne renommée de subway_station\n",
    "    subway_station.at[index, 'surrounding bike stations'] = count\n",
    "\n",
    "# Afficher le dataframe mis à jour\n",
    "print(subway_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_excel in module pandas.io.excel._base:\n",
      "\n",
      "read_excel(io, sheet_name: 'str | int | list[IntStrT] | None' = 0, *, header: 'int | Sequence[int] | None' = 0, names: 'list[str] | None' = None, index_col: 'int | Sequence[int] | None' = None, usecols: 'int | str | Sequence[int] | Sequence[str] | Callable[[str], bool] | None' = None, dtype: 'DtypeArg | None' = None, engine: \"Literal['xlrd', 'openpyxl', 'odf', 'pyxlsb'] | None\" = None, converters: 'dict[str, Callable] | dict[int, Callable] | None' = None, true_values: 'Iterable[Hashable] | None' = None, false_values: 'Iterable[Hashable] | None' = None, skiprows: 'Sequence[int] | int | Callable[[int], object] | None' = None, nrows: 'int | None' = None, na_values=None, keep_default_na: 'bool' = True, na_filter: 'bool' = True, verbose: 'bool' = False, parse_dates: 'list | dict | bool' = False, date_parser: 'Callable | lib.NoDefault' = <no_default>, date_format: 'dict[Hashable, str] | str | None' = None, thousands: 'str | None' = None, decimal: 'str' = '.', comment: 'str | None' = None, skipfooter: 'int' = 0, storage_options: 'StorageOptions' = None, dtype_backend: 'DtypeBackend | lib.NoDefault' = <no_default>) -> 'DataFrame | dict[IntStrT, DataFrame]'\n",
      "    Read an Excel file into a pandas DataFrame.\n",
      "    \n",
      "    Supports `xls`, `xlsx`, `xlsm`, `xlsb`, `odf`, `ods` and `odt` file extensions\n",
      "    read from a local filesystem or URL. Supports an option to read\n",
      "    a single sheet or a list of sheets.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    io : str, bytes, ExcelFile, xlrd.Book, path object, or file-like object\n",
      "        Any valid string path is acceptable. The string could be a URL. Valid\n",
      "        URL schemes include http, ftp, s3, and file. For file URLs, a host is\n",
      "        expected. A local file could be: ``file://localhost/path/to/table.xlsx``.\n",
      "    \n",
      "        If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
      "    \n",
      "        By file-like object, we refer to objects with a ``read()`` method,\n",
      "        such as a file handle (e.g. via builtin ``open`` function)\n",
      "        or ``StringIO``.\n",
      "    sheet_name : str, int, list, or None, default 0\n",
      "        Strings are used for sheet names. Integers are used in zero-indexed\n",
      "        sheet positions (chart sheets do not count as a sheet position).\n",
      "        Lists of strings/integers are used to request multiple sheets.\n",
      "        Specify None to get all worksheets.\n",
      "    \n",
      "        Available cases:\n",
      "    \n",
      "        * Defaults to ``0``: 1st sheet as a `DataFrame`\n",
      "        * ``1``: 2nd sheet as a `DataFrame`\n",
      "        * ``\"Sheet1\"``: Load sheet with name \"Sheet1\"\n",
      "        * ``[0, 1, \"Sheet5\"]``: Load first, second and sheet named \"Sheet5\"\n",
      "          as a dict of `DataFrame`\n",
      "        * None: All worksheets.\n",
      "    \n",
      "    header : int, list of int, default 0\n",
      "        Row (0-indexed) to use for the column labels of the parsed\n",
      "        DataFrame. If a list of integers is passed those row positions will\n",
      "        be combined into a ``MultiIndex``. Use None if there is no header.\n",
      "    names : array-like, default None\n",
      "        List of column names to use. If file contains no header row,\n",
      "        then you should explicitly pass header=None.\n",
      "    index_col : int, list of int, default None\n",
      "        Column (0-indexed) to use as the row labels of the DataFrame.\n",
      "        Pass None if there is no such column.  If a list is passed,\n",
      "        those columns will be combined into a ``MultiIndex``.  If a\n",
      "        subset of data is selected with ``usecols``, index_col\n",
      "        is based on the subset.\n",
      "    \n",
      "        Missing values will be forward filled to allow roundtripping with\n",
      "        ``to_excel`` for ``merged_cells=True``. To avoid forward filling the\n",
      "        missing values use ``set_index`` after reading the data instead of\n",
      "        ``index_col``.\n",
      "    usecols : str, list-like, or callable, default None\n",
      "        * If None, then parse all columns.\n",
      "        * If str, then indicates comma separated list of Excel column letters\n",
      "          and column ranges (e.g. \"A:E\" or \"A,C,E:F\"). Ranges are inclusive of\n",
      "          both sides.\n",
      "        * If list of int, then indicates list of column numbers to be parsed\n",
      "          (0-indexed).\n",
      "        * If list of string, then indicates list of column names to be parsed.\n",
      "        * If callable, then evaluate each column name against it and parse the\n",
      "          column if the callable returns ``True``.\n",
      "    \n",
      "        Returns a subset of the columns according to behavior above.\n",
      "    dtype : Type name or dict of column -> type, default None\n",
      "        Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32}\n",
      "        Use `object` to preserve data as stored in Excel and not interpret dtype.\n",
      "        If converters are specified, they will be applied INSTEAD\n",
      "        of dtype conversion.\n",
      "    engine : str, default None\n",
      "        If io is not a buffer or path, this must be set to identify io.\n",
      "        Supported engines: \"xlrd\", \"openpyxl\", \"odf\", \"pyxlsb\".\n",
      "        Engine compatibility :\n",
      "    \n",
      "        - \"xlrd\" supports old-style Excel files (.xls).\n",
      "        - \"openpyxl\" supports newer Excel file formats.\n",
      "        - \"odf\" supports OpenDocument file formats (.odf, .ods, .odt).\n",
      "        - \"pyxlsb\" supports Binary Excel files.\n",
      "    \n",
      "        .. versionchanged:: 1.2.0\n",
      "            The engine `xlrd <https://xlrd.readthedocs.io/en/latest/>`_\n",
      "            now only supports old-style ``.xls`` files.\n",
      "            When ``engine=None``, the following logic will be\n",
      "            used to determine the engine:\n",
      "    \n",
      "           - If ``path_or_buffer`` is an OpenDocument format (.odf, .ods, .odt),\n",
      "             then `odf <https://pypi.org/project/odfpy/>`_ will be used.\n",
      "           - Otherwise if ``path_or_buffer`` is an xls format,\n",
      "             ``xlrd`` will be used.\n",
      "           - Otherwise if ``path_or_buffer`` is in xlsb format,\n",
      "             ``pyxlsb`` will be used.\n",
      "    \n",
      "             .. versionadded:: 1.3.0\n",
      "           - Otherwise ``openpyxl`` will be used.\n",
      "    \n",
      "             .. versionchanged:: 1.3.0\n",
      "    \n",
      "    converters : dict, default None\n",
      "        Dict of functions for converting values in certain columns. Keys can\n",
      "        either be integers or column labels, values are functions that take one\n",
      "        input argument, the Excel cell content, and return the transformed\n",
      "        content.\n",
      "    true_values : list, default None\n",
      "        Values to consider as True.\n",
      "    false_values : list, default None\n",
      "        Values to consider as False.\n",
      "    skiprows : list-like, int, or callable, optional\n",
      "        Line numbers to skip (0-indexed) or number of lines to skip (int) at the\n",
      "        start of the file. If callable, the callable function will be evaluated\n",
      "        against the row indices, returning True if the row should be skipped and\n",
      "        False otherwise. An example of a valid callable argument would be ``lambda\n",
      "        x: x in [0, 2]``.\n",
      "    nrows : int, default None\n",
      "        Number of rows to parse.\n",
      "    na_values : scalar, str, list-like, or dict, default None\n",
      "        Additional strings to recognize as NA/NaN. If dict passed, specific\n",
      "        per-column NA values. By default the following values are interpreted\n",
      "        as NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
      "        '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'None',\n",
      "        'n/a', 'nan', 'null'.\n",
      "    keep_default_na : bool, default True\n",
      "        Whether or not to include the default NaN values when parsing the data.\n",
      "        Depending on whether `na_values` is passed in, the behavior is as follows:\n",
      "    \n",
      "        * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
      "          is appended to the default NaN values used for parsing.\n",
      "        * If `keep_default_na` is True, and `na_values` are not specified, only\n",
      "          the default NaN values are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are specified, only\n",
      "          the NaN values specified `na_values` are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are not specified, no\n",
      "          strings will be parsed as NaN.\n",
      "    \n",
      "        Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
      "        `na_values` parameters will be ignored.\n",
      "    na_filter : bool, default True\n",
      "        Detect missing value markers (empty strings and the value of na_values). In\n",
      "        data without any NAs, passing na_filter=False can improve the performance\n",
      "        of reading a large file.\n",
      "    verbose : bool, default False\n",
      "        Indicate number of NA values placed in non-numeric columns.\n",
      "    parse_dates : bool, list-like, or dict, default False\n",
      "        The behavior is as follows:\n",
      "    \n",
      "        * bool. If True -> try parsing the index.\n",
      "        * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
      "          each as a separate date column.\n",
      "        * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
      "          a single date column.\n",
      "        * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
      "          result 'foo'\n",
      "    \n",
      "        If a column or index contains an unparsable date, the entire column or\n",
      "        index will be returned unaltered as an object data type. If you don`t want to\n",
      "        parse some cells as date just change their type in Excel to \"Text\".\n",
      "        For non-standard datetime parsing, use ``pd.to_datetime`` after ``pd.read_excel``.\n",
      "    \n",
      "        Note: A fast-path exists for iso8601-formatted dates.\n",
      "    date_parser : function, optional\n",
      "        Function to use for converting a sequence of string columns to an array of\n",
      "        datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "        conversion. Pandas will try to call `date_parser` in three different ways,\n",
      "        advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
      "        string values from the columns defined by `parse_dates` into a single array\n",
      "        and pass that; and 3) call `date_parser` once for each row using one or\n",
      "        more strings (corresponding to the columns defined by `parse_dates`) as\n",
      "        arguments.\n",
      "    \n",
      "        .. deprecated:: 2.0.0\n",
      "           Use ``date_format`` instead, or read in as ``object`` and then apply\n",
      "           :func:`to_datetime` as-needed.\n",
      "    date_format : str or dict of column -> format, default ``None``\n",
      "       If used in conjunction with ``parse_dates``, will parse dates according to this\n",
      "       format. For anything more complex,\n",
      "       please read in as ``object`` and then apply :func:`to_datetime` as-needed.\n",
      "    \n",
      "       .. versionadded:: 2.0.0\n",
      "    thousands : str, default None\n",
      "        Thousands separator for parsing string columns to numeric.  Note that\n",
      "        this parameter is only necessary for columns stored as TEXT in Excel,\n",
      "        any numeric columns will automatically be parsed, regardless of display\n",
      "        format.\n",
      "    decimal : str, default '.'\n",
      "        Character to recognize as decimal point for parsing string columns to numeric.\n",
      "        Note that this parameter is only necessary for columns stored as TEXT in Excel,\n",
      "        any numeric columns will automatically be parsed, regardless of display\n",
      "        format.(e.g. use ',' for European data).\n",
      "    \n",
      "        .. versionadded:: 1.4.0\n",
      "    \n",
      "    comment : str, default None\n",
      "        Comments out remainder of line. Pass a character or characters to this\n",
      "        argument to indicate comments in the input file. Any data between the\n",
      "        comment string and the end of the current line is ignored.\n",
      "    skipfooter : int, default 0\n",
      "        Rows at the end to skip (0-indexed).\n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "        URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "        forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "        details, and for more examples on storage options refer `here\n",
      "        <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "        highlight=storage_options#reading-writing-remote-files>`_.\n",
      "    \n",
      "        .. versionadded:: 1.2.0\n",
      "    \n",
      "    dtype_backend : {\"numpy_nullable\", \"pyarrow\"}, defaults to NumPy backed DataFrames\n",
      "        Which dtype_backend to use, e.g. whether a DataFrame should have NumPy\n",
      "        arrays, nullable dtypes are used for all dtypes that have a nullable\n",
      "        implementation when \"numpy_nullable\" is set, pyarrow is used for all\n",
      "        dtypes if \"pyarrow\" is set.\n",
      "    \n",
      "        The dtype_backends are still experimential.\n",
      "    \n",
      "        .. versionadded:: 2.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or dict of DataFrames\n",
      "        DataFrame from the passed in Excel file. See notes in sheet_name\n",
      "        argument for more information on when a dict of DataFrames is returned.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.to_excel : Write DataFrame to an Excel file.\n",
      "    DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "    read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      "    read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    The file can be read using the file name as string or an open file object:\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=0)  # doctest: +SKIP\n",
      "           Name  Value\n",
      "    0   string1      1\n",
      "    1   string2      2\n",
      "    2  #Comment      3\n",
      "    \n",
      "    >>> pd.read_excel(open('tmp.xlsx', 'rb'),\n",
      "    ...               sheet_name='Sheet3')  # doctest: +SKIP\n",
      "       Unnamed: 0      Name  Value\n",
      "    0           0   string1      1\n",
      "    1           1   string2      2\n",
      "    2           2  #Comment      3\n",
      "    \n",
      "    Index and header can be specified via the `index_col` and `header` arguments\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=None, header=None)  # doctest: +SKIP\n",
      "         0         1      2\n",
      "    0  NaN      Name  Value\n",
      "    1  0.0   string1      1\n",
      "    2  1.0   string2      2\n",
      "    3  2.0  #Comment      3\n",
      "    \n",
      "    Column types are inferred but can be explicitly specified\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=0,\n",
      "    ...               dtype={'Name': str, 'Value': float})  # doctest: +SKIP\n",
      "           Name  Value\n",
      "    0   string1    1.0\n",
      "    1   string2    2.0\n",
      "    2  #Comment    3.0\n",
      "    \n",
      "    True, False, and NA values, and thousands separators have defaults,\n",
      "    but can be explicitly specified, too. Supply the values you would like\n",
      "    as strings or lists of strings!\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=0,\n",
      "    ...               na_values=['string1', 'string2'])  # doctest: +SKIP\n",
      "           Name  Value\n",
      "    0       NaN      1\n",
      "    1       NaN      2\n",
      "    2  #Comment      3\n",
      "    \n",
      "    Comment lines in the excel input file can be skipped using the `comment` kwarg\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=0, comment='#')  # doctest: +SKIP\n",
      "          Name  Value\n",
      "    0  string1    1.0\n",
      "    1  string2    2.0\n",
      "    2     None    NaN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.read_excel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
