{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import folium\n",
    "from folium.plugins import FastMarkerCluster\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "import utm \n",
    "import os\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Generate_basemap():\n",
    "#     basemap = folium.Map(location=[40.730610 , -73.935242])\n",
    "#     return basemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 List of Stations (Lat,Lon,Capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the JSON file\n",
    "url = 'https://gbfs.lyft.com/gbfs/2.3/bkn/en/station_information.json'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    json_data = response.json()\n",
    "    \n",
    "    # Now you can work with the JSON data)\n",
    "else:\n",
    "    print('Failed to retrieve data:', response.status_code)\n",
    "\n",
    "# Create a DataFrame from the 'stations' list\n",
    "station_data = pd.DataFrame(json_data['data']['stations'])\n",
    "\n",
    "# Select only the required columns\n",
    "station_data = station_data[['short_name', 'name', 'region_id', 'lat', 'lon', 'capacity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Station Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basemap = Generate_basemap()\n",
    "# FastMarkerCluster(station_data[['lat', 'lon' , 'capacity']]).add_to(basemap)\n",
    "\n",
    "# HeatMap(station_data[['lat', 'lon' , 'capacity']]).add_to(basemap)\n",
    "# # basemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Ride Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Ride Data (2015-2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# # Open all files / computing intensive\n",
    "# current_directory = os.getcwd()\n",
    "# file_name = \"data\"\n",
    "# base_folder_path = os.path.join(current_directory, file_name)\n",
    "# start_year = 2015\n",
    "# end_year = 2019\n",
    "# combined_data = combine_csv_files_in_years(base_folder_path,start_year,end_year)\n",
    "# len(combined_data)\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From 2015 - 2021, 15 columns\n",
    "# From 2022 - 2024, 13 columns\n",
    "# Issues with 2017\n",
    "# Issues with 2021\n",
    "\n",
    "# current_directory = os.getcwd()\n",
    "# file_name = \"data//2016\"\n",
    "# folder_path = os.path.join(current_directory, file_name)\n",
    "\n",
    "# data = combine_csv_files(folder_path)\n",
    "# data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_data['starttime'] = pd.to_datetime(combined_data['starttime'])\n",
    "# combined_data['stoptime'] = pd.to_datetime(combined_data['stoptime'])\n",
    "\n",
    "# # Reduce memory usage\n",
    "# cols = ['start station name', 'end station name', 'bikeid', 'usertype', 'gender']\n",
    "# for col in cols:\n",
    "#     combined_data[col] = combined_data[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Ride Data (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_directory = os.getcwd()\n",
    "# file_name = \"data/2020/data_2020.pkl\"\n",
    "# folder_path = os.path.join(current_directory, file_name)\n",
    "\n",
    "# # Load the DataFrame from the pickle file\n",
    "# data_2020 = pd.read_pickle(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################\n",
    "# current_directory = os.getcwd()\n",
    "# file_name = \"data/2020\"\n",
    "# folder_path = os.path.join(current_directory, file_name)\n",
    "\n",
    "# data_2020 = combine_csv_files(folder_path)\n",
    "# data_2020.iloc[:3]\n",
    "# data_2020['starttime'] = pd.to_datetime(data_2020['starttime'])\n",
    "# data_2020['stoptime'] = pd.to_datetime(data_2020['stoptime'])\n",
    "\n",
    "# # Reduce memory usage\n",
    "# cols = ['start station name', 'end station name', 'bikeid', 'usertype', 'gender']\n",
    "# for col in cols:\n",
    "#     data_2020[col] = data_2020[col].astype('category')\n",
    "\n",
    "# # Define the file path\n",
    "# current_directory = os.getcwd()\n",
    "# file_name = \"data/2020/data_2020.pkl\"\n",
    "# file_path = os.path.join(current_directory, file_name)\n",
    "\n",
    "# # Save the DataFrame as a pickle file\n",
    "# data_2020.to_pickle(file_path)\n",
    "# #############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Ride Data (2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_directory = os.getcwd()\n",
    "# file_name = \"data/2021/data_2021.pkl\"\n",
    "# folder_path = os.path.join(current_directory, file_name)\n",
    "\n",
    "# # Load the DataFrame from the pickle file\n",
    "# data_2021 = pd.read_pickle(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n",
      "C:\\Users\\lukas\\AppData\\Local\\Temp\\ipykernel_28284\\3268837191.py:23: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(folder_path, file))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_station_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_station_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_station_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_station_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mride_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrideable_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmember_casual\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols:\n\u001b[1;32m---> 14\u001b[0m     data_2021[col] \u001b[38;5;241m=\u001b[39m \u001b[43mdata_2021\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Define the file path\u001b[39;00m\n\u001b[0;32m     17\u001b[0m current_directory \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6530\u001b[0m     results \u001b[38;5;241m=\u001b[39m [ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[0;32m   6532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6533\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6534\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6535\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    412\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    614\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 616\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    618\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    620\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\dtypes\\astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    235\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\dtypes\\astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\dtypes\\astype.py:80\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# dispatch on extension dtype if needed\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct_array_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype must be np.dtype or ExtensionDtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arrays\\categorical.py:510\u001b[0m, in \u001b[0;36mCategorical._from_sequence\u001b[1;34m(cls, scalars, dtype, copy)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_sequence\u001b[39m(\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;28mcls\u001b[39m, scalars, \u001b[38;5;241m*\u001b[39m, dtype: Dtype \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    509\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m--> 510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscalars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arrays\\categorical.py:449\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[1;34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[0m\n\u001b[0;32m    447\u001b[0m     values \u001b[38;5;241m=\u001b[39m sanitize_array(values, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 449\u001b[0m     codes, categories \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    451\u001b[0m     codes, categories \u001b[38;5;241m=\u001b[39m factorize(values, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\algorithms.py:795\u001b[0m, in \u001b[0;36mfactorize\u001b[1;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[0;32m    793\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[1;32m--> 795\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    802\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m safe_sort(\n\u001b[0;32m    803\u001b[0m         uniques,\n\u001b[0;32m    804\u001b[0m         codes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    808\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\algorithms.py:604\u001b[0m, in \u001b[0;36mfactorize_array\u001b[1;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    595\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mfactorize(\n\u001b[0;32m    596\u001b[0m     values,\n\u001b[0;32m    597\u001b[0m     na_sentinel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    600\u001b[0m     ignore_na\u001b[38;5;241m=\u001b[39muse_na_sentinel,\n\u001b[0;32m    601\u001b[0m )\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[1;32m--> 604\u001b[0m uniques \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43muniques\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    606\u001b[0m codes \u001b[38;5;241m=\u001b[39m ensure_platform_int(codes)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m codes, uniques\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\algorithms.py:184\u001b[0m, in \u001b[0;36m_reconstruct_data\u001b[1;34m(values, dtype, original)\u001b[0m\n\u001b[0;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ensure_object(values)\n\u001b[1;32m--> 184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_reconstruct_data\u001b[39m(\n\u001b[0;32m    185\u001b[0m     values: ArrayLike, dtype: DtypeObj, original: AnyArrayLike\n\u001b[0;32m    186\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m    187\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03m    reverse of _ensure_data\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m    ExtensionArray or np.ndarray\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, ABCExtensionArray) \u001b[38;5;129;01mand\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtype:\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;66;03m# Catch DatetimeArray/TimedeltaArray\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# #############################################\n",
    "# current_directory = os.getcwd()\n",
    "# file_name = \"data/2021\"\n",
    "# folder_path = os.path.join(current_directory, file_name)\n",
    "\n",
    "# data_2021 = combine_csv_files(folder_path)\n",
    "\n",
    "\n",
    "# data_2021['started_at'] = pd.to_datetime(data_2021['started_at'])\n",
    "# data_2021['ended_at'] = pd.to_datetime(data_2021['ended_at'])\n",
    "\n",
    "# cols = ['start_station_name', 'end_station_name', 'start_station_id', 'end_station_id', 'ride_id', 'rideable_type', 'member_casual']\n",
    "# for col in cols:\n",
    "#     data_2021[col] = data_2021[col].astype('category')\n",
    "\n",
    "# # Define the file path\n",
    "# current_directory = os.getcwd()\n",
    "# file_name = \"data/2021/data_2021.pkl\"\n",
    "# file_path = os.path.join(current_directory, file_name)\n",
    "\n",
    "# # Save the DataFrame as a pickle file\n",
    "# data_2021.to_pickle(file_path)\n",
    "# #############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Ride Data (2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open only 2024\n",
    "#############################################\n",
    "# current_directory = os.getcwd()\n",
    "# file_name = \"data/2024\"\n",
    "# folder_path = os.path.join(current_directory, file_name)\n",
    "\n",
    "# data_2024 = combine_csv_files(folder_path)\n",
    "\n",
    "# data_2024['started_at'] = pd.to_datetime(data_2024['started_at'])\n",
    "# data_2024['ended_at'] = pd.to_datetime(data_2024['ended_at'])\n",
    "\n",
    "# cols = ['start_station_name', 'end_station_name', 'start_station_id', 'end_station_id', 'ride_id', 'rideable_type', 'member_casual']\n",
    "# for col in cols:\n",
    "#     data_2024[col] = data_2024[col].astype('category')\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data_2024['start_lat'] = pd.to_numeric(data_2024[\"start_lat\"])\n",
    "# data_2024['end_lat'] = pd.to_numeric(data_2024[\"end_lat\"])\n",
    "# data_2024['start_lng'] = pd.to_numeric(data_2024[\"start_lng\"])\n",
    "# data_2024['end_lng'] = pd.to_numeric(data_2024[\"end_lng\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4. Ride Data (2019) - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = os.path.join(os.getcwd(), \"data\", \"2019\")\n",
    "\n",
    "# List all files in the folder\n",
    "file_names = os.listdir(folder_path)\n",
    "\n",
    "# Initialize an empty list to store DataFrame chunks\n",
    "chunks = []\n",
    "\n",
    "# Loop through each file, load it, and append it to the list\n",
    "for file_name in file_names:\n",
    "    if file_name.endswith(\".pkl.gz\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        chunk = pd.read_pickle(file_path, compression='gzip')\n",
    "        chunks.append(chunk)\n",
    "\n",
    "# Concatenate all DataFrame chunks into a single DataFrame\n",
    "data_2019 = pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the DataFrame into six chunks\n",
    "# chunk_size = len(data_2019) // 6\n",
    "# chunks = [data_2019[i:i+chunk_size] for i in range(0, len(data_2019), chunk_size)]\n",
    "\n",
    "# # Define the folder path where the split files will be saved\n",
    "# folder_path = os.path.join(os.getcwd(), \"data\", \"2019\")\n",
    "\n",
    "# # Save each chunk as a separate gzip-compressed pickle file\n",
    "# for i, chunk in enumerate(chunks):\n",
    "#     chunk_file_name = f\"data_2019_chunk_{i}.pkl.gz\"\n",
    "#     chunk_file_path = os.path.join(folder_path, chunk_file_name)\n",
    "#     chunk.to_pickle(chunk_file_path, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_directory = os.getcwd()\n",
    "# file_name = \"data/2019/data_2019.pkl\"\n",
    "# folder_path = os.path.join(current_directory, file_name)\n",
    "# data_2019.to_pickle(folder_path, compression='gzip')\n",
    "\n",
    "# current_directory = os.getcwd()\n",
    "# file_name = \"data/2019/data_2019.pkl\"\n",
    "# folder_path = os.path.join(current_directory, file_name)\n",
    "\n",
    "# # Load the DataFrame from the pickle file\n",
    "# # data_2019 = pd.read_pickle(folder_path)\n",
    "# data_2019 = pd.read_pickle(folder_path, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open only 2019\n",
    "\n",
    "# current_directory = os.getcwd()\n",
    "# file_name = \"data/2019\"\n",
    "# folder_path = os.path.join(current_directory, file_name)\n",
    "\n",
    "# data_2019 = combine_csv_files(folder_path)\n",
    "# data_2019.iloc[:3]\n",
    "\n",
    "# # Reduce memory usage\n",
    "# data_2019['starttime'] = pd.to_datetime(data_2019['starttime'])\n",
    "# data_2019['stoptime'] = pd.to_datetime(data_2019['stoptime'])\n",
    "\n",
    "# cols = ['start station name', 'end station name', 'bikeid', 'usertype', 'gender']\n",
    "# for col in cols:\n",
    "#     data_2019[col] = data_2019[col].astype('category')\n",
    "\n",
    "# # Define the file path\n",
    "# current_directory = os.getcwd()\n",
    "# file_name = \"data/2019/data_2019.pkl\"\n",
    "# file_path = os.path.join(current_directory, file_name)\n",
    "\n",
    "# # Save the DataFrame as a pickle file\n",
    "# data_2019.to_pickle(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessible dataframes    Description                            # of columns  \n",
      "data_2019                Gives data for 2019-Baseline           15\n",
      "station_data             Existing stations in NYC from Lyft      6\n"
     ]
    }
   ],
   "source": [
    "print(\"Accessible dataframes    Description                            # of columns  \")\n",
    "# print(\"combined_data            Gives combined data from 2015-2019     15\")\n",
    "# print(\"data_2021                Gives data for 2021                    15\")\n",
    "print(\"data_2020                Gives data for 2020                    15\")\n",
    "# print(\"data_2024                Gives data for 2024                    13\")\n",
    "print(\"data_2019                Gives data for 2019-Baseline           15\")\n",
    "print(\"station_data             Existing stations in NYC from Lyft      6\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
